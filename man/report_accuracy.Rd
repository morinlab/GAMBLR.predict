% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/plotting.R
\name{report_accuracy}
\alias{report_accuracy}
\title{Report Classification Accuracy and Per-Class Metrics}
\usage{
report_accuracy(
  predictions,
  truth = "lymphgen",
  pred = "DLBCLone_io",
  per_group = FALSE,
  metric = "accuracy",
  verbose = FALSE
)
}
\arguments{
\item{predictions}{Data frame containing predicted and true class labels.}

\item{truth}{Name of the column with true class labels (default: "lymphgen").}

\item{pred}{Name of the column with predicted class labels (default: "predicted_label").}

\item{per_group}{Logical; if TRUE, computes per-group accuracy metrics.}

\item{metric}{Character; type of accuracy to report ("accuracy" supported).}

\item{verbose}{Whether to print verbose outputs to console}
}
\value{
A list with:
\item{no_other}{Accuracy excluding samples assigned to "Other"}
\item{per_class}{Balanced accuracy per class}
\item{per_class_sensitivity}{Sensitivity per class}
\item{overall}{Overall accuracy including all samples}
}
\description{
Computes overall accuracy, balanced accuracy, and sensitivity for predicted vs. true class labels.
Optionally excludes samples assigned to the "Other" class from accuracy calculations.
}
\details{
\itemize{
\item Uses confusion matrices to compute accuracy metrics.
\item Excludes "Other" class for no_other accuracy.
\item Returns per-class metrics for further analysis.
}
}
\examples{
result <- report_accuracy(predictions_df)
result$overall
result$per_class

}
