---
title: "DLBCLone: Full Walkthrough"
vignette: >
  %\VignetteIndexEntry{quarto vignettes}
  %\VignetteEngine{quarto::html}
  %\VignetteEncoding{UTF-8}
from: markdown+emoji
fig.align: "center"
---

```{r set working directory and libs, echo=FALSE, include=FALSE, cahce=FALSE}
library(GAMBLR.predict)
library(GAMBLR.helpers) 
library(tidyverse)

default_model <- "best_opt_w"

all_features_optimized <- DLBCLone_load_optimized(
        dirname(
            system.file(
                "extdata/models",
                "best_opt_model.rds",
                package = "GAMBLR.predict"
            )
        ),
        default_model
    )

#all_features_optimized <- DLBCLone_activate(loaded_model, force = TRUE)

model_feats = grep("_feats",colnames(all_features_optimized$features),invert=T,value=T)
```

*A step by step example workflow from start to finish*

```{r, echo=TRUE, message=FALSE, warning=FALSE, results='hide'}
library(GAMBLR.open)
library(tidyverse)
```

## Training data

For simplicity, we'll skip feature selection and train our new model using a set of genes that have been pre-selected for you based on a model described in the [DLBCLone preprint](https://www.medrxiv.org/content/10.1101/2025.09.18.25335809v1). The code below shows how to infer what features were used in training our model, starting with the column names of the model's features (`model_feats`).

SSM features

```{r, echo=TRUE, message=FALSE, warning=FALSE}

# Full set of genes considered for SSM

model_genes = grep("_SV|HOTS",model_feats,invert=T,value=T)

model_genes
```

Hotspot features

```{r, echo=TRUE, message=FALSE, warning=FALSE}
# Genes with hotspots considered

hotspot_features = grep("HOTS",model_feats,invert=F,value=T) 
hotspot_features
```

SV features

```{r, echo=TRUE, message=FALSE, warning=FALSE}

SV_genes = grep("_SV",model_feats,invert=F,value=T)
SV_genes

```

## Load and subset the training data

The GAMBLR.predict package is bundled with base-3 mutation status matrix for the training data set. The code below shows how to load that into a data frame (setting sample_id as the row names) and subset it to only the features described above. 

```{r,message=FALSE, warning=FALSE, results='hide'}

best_opt_model_matrix <- readr::read_tsv(
  system.file("extdata/all_full_status.tsv",
             package = "GAMBLR.predict")) %>%
  tibble::column_to_rownames("sample_id") 

# keep only the columns you want to use for your model
best_opt_model_matrix = best_opt_model_matrix  %>%
  select(all_of(model_genes),all_of(hotspot_features),all_of(SV_genes))

```

To train a model, we also need ground truth labels. These come from another bundled file, which is the sample metadata for the samples in the mutation matrix we just loaded. 

```{r, message=FALSE, warning=FALSE, results='hide'}
dlbcl_meta <- readr::read_tsv(system.file("extdata/dlbcl_meta_with_dlbclass.tsv",package = "GAMBLR.predict"))

# remove rows that don't correspond to unambiguous classes (i.e. drop composites)
dlbcl_meta_clean <- filter(
  dlbcl_meta,
  lymphgen %in% c("MCD","EZB","BN2","N1","ST2","Other")
)
```



## `make_and_annotate_umap`
```{r umap1, message=FALSE, warning=FALSE,results='hide'}
mu_everything = make_and_annotate_umap(
  best_opt_model_matrix,
  dlbcl_meta_clean,
  core_features = list(
    ST2=c("SGK1","DUSP2","TET2","SOCS1"),
    N1="NOTCH1",
    EZB=c("EZH2","BCL2_SV"),
    MCD=c("MYD88HOTSPOT","CD79B","PIM1"),
    BN2=c("BCL6_SV","NOTCH2","SPEN","CD70")
  )
)
```

## make_umap_scatterplot 

```{r}
make_umap_scatterplot(
  mu_everything$df,
  drop_other = F
)
```

## DLBCLone_optimize_params 

```{r optimize1, eval = FALSE}
all_features_optimized = DLBCLone_optimize_params(  
  mu_everything$features, 
  dlbcl_meta_clean,
  umap_out = mu_everything,
  truth_classes = c("MCD","EZB","BN2","N1","ST2","Other"),
  optimize_for_other = T,
  min_k=5,
  max_k=13
)
```

## make_alluvial

DLBCLone with outgroup optimization ("wo") w for weighted, o for optimized for other.
```{r plot_alluvial2, message=FALSE, warning=FALSE,results='hide'}
make_alluvial(all_features_optimized,pred_column = "DLBCLone_wo",pred_name = "DLBCLone_wo")
```

## DLBCLone_predict

### predicting one training sample
```{r, message=FALSE, warning=FALSE}
test_sample = "00-14595_tumorC"

pred_train <- DLBCLone_predict(
  mutation_status = best_opt_model_matrix[test_sample,],
  optimized_model = all_features_optimized
)
knitr::kable(head(pred_train$prediction))
```

## make_neighborhood_plot 
```{r}
make_neighborhood_plot(
  single_sample_prediction_output = pred_train,
  this_sample_id = "00-14595_tumorC",
  prediction_in_title = TRUE,
  add_circle = TRUE,
  label_column = "DLBCLone_wo"
)
```

## nearest_neighbor_heatmap 

```{r, message=FALSE,warning=FALSE}
nearest_neighbor_heatmap(
  this_sample_id = "00-14595_tumorC",
  DLBCLone_model = pred_train,
  font_size = 10
)
```
